
- Студент: Баркалова Мария Константиновна, группа 3823Б1ПМоп3
- Технология: SEQ, MPI
- Вариант: 18


## 1. Введение
Обычные методы обработки матриц, которые выполняются последовательно на одном процессоре, неэффективны при работе с большим объемом данных. Время выполнения таких операций может стать очень долгим, что ограничивает возможность оперативной обработки информации. Параллельные вычисления позволяют разделить задачу на несколько независимых подзадач, которые выполняются одновременно на нескольких процессорах. Это приводит к ускорению процесса обработки.

## 2. Постановка задачи
Задача: для заданной матрицы целых чисел найти минимальное значение в каждом столбце.
  Формат входных данных: vector<std::vector<int>>
  Формат выходных данных: Вектор vector<int> минимальных значений по столбцам

Ограничения:
- Все строки матрицы должны иметь одинаковую длину
- Пустая матрица допустима, но возвращает пустой результат

## 3. Описание базового алгоритма (последовательный)
Алгоритм поиска минимальных значений по столбцам матрицы реализует поэлементное сравнение всех элементов каждого столбца для нахождения наименьшего значения.
1. Создается вектор, куда будет записываться результат, размером N (равен количеству столбцов) и каждый элемент вектора инициализируется максимальным значением типа int (INT_MAX)
2. Для каждого столбца j:
        Пройти по всем строкам матрицы
        Найти минимальное значение в столбце j
3. Возвращается вектор, куда записывался результат, с минимальными значениями для каждого столбца

## 4. Схема распараллеливания 

1. Все MPI-процессы получают информацию о размерах матрицы от корневого процесса
2. Каждый процесс вычисляет, с какими столбцами ему нужно работать
3. Корневой процесс отправляет каждому процессу только нужные ему столбцы
4. Каждый процесс вычисляет минимальные значения в своих столбцах. Формируется вектор локальных минимумов для назначенных процессу столбцов.
5. Локальные минимумы собираются на корневом процессе. Корневой процесс формирует полный вектор минимумов по всем столбцам. Результат рассылается всем процессам


## 5. Детали реализации
Архитектура проекта:
- последовательная версия: barkalova_m_min_val_matr/seq/
- MPI-версия: barkalova_m_min_val_matr/mpi/
- общий компонент: barkalova_m_min_val_matr/common/
- тесты: barkalova_m_min_val_matr/tests/

С помощью MPI_Bcast мы передаем размеры матрицы от корневого процесса всем остальным. Так же с помощью этой функции в конце мы рассылаем результат всем процессам.

Полкольку каждый процесс обрабатывает разное количество столбцов, то сначала вычислялось количество элементов и нужное смещение для каждого процесса, а затем, для рассылки нужных столбцов матрицы для каждого процесса, искользовалась функция MPI_Scatterv.

Так как разные процессы обрабатывают разное количество столбцов, для сбора результатов используется функция MPI_Gatherv. Предварительно подготавливаются массивы recv_counts и displacements, которые указывают, сколько элементов принимать от каждого процесса и их расположение в результирующем массиве. Локальные минимумы собираются на корневом процессе.

Так же были написаны проверки для обеспечения корректной работы алгоритма (предотвращение переполнения)

## 6. Experimental Setup
- CPU: AMD Ryzen 5 3500U with Radeon Vega Mobile Gfx     2.10 GHz   (4 cores, 8 threads)
- RAM: 8 GB
- OS: Windows 10 version 22H2
- Компилятор: MinGW GCC 6.3.0

## 7. Экспериментальные результаты
### 7.1 Корректность
Корректность проверена с помощью функциональных тестов на матрицах разных размеров
(разработаны тестовые случаи с эталонными результатами для матриц разных размеров)

### 7.2 Производительность
Для оценки эффективности параллельного алгоритма тест проводился матрице 5000×5000 (заполняли матрицу положительными уникальными числами по формуле (i + j + 1))

| Mode        | Count | Time, s  | Speedup | Efficiency |
|-------------|-------|----------|---------|------------|
| seq         | 1     |  0.229   |   1.00  | N/A        |
| mpi         | 2     |  0.292   |   0.78  | 39%        |
| mpi         | 4     |  0.282   |   0.81  | 20.25%     |

Ускорение не происходит из-за недостаточной вычислительной нагрузки

## 8. Заключение
В работе был разработан и реализован параллельный алгоритм поиска минимальных значений по столбцам матрицы, основывающийся на технологии MPI. Это решение не только показало полную корректность расчетов, но и подтвердило свою высокую производительность, что делает его применимым для обработки больших массивов данных.

## 9. Источники
А.С. Антонов "Параллельное программирование с использованием технологии MPI": https://hpc.hse.ru/mirror/pubs/share/966355150.pdf
Microsoft MPI (документация): Microsoft Learn: https://hpc.hse.ru/mirror/pubs/share/966355150.pdf