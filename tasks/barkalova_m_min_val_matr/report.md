## Введение
Обычные методы обработки матриц, которые выполняются последовательно на одном процессоре неэффективными при работе с большим объемом данных. Время выполнения таких операций может стать очень долгим, что ограничивает возможность оперативной обработки информации. Параллельные вычисления позволяют разделить задачу на несколько независимых подзадач, которые выполняются одновременно на нескольких процессорах. Это приводит к ускорению процесса обработки.

## Постановка задачи
На вход подается матрица размерности M×N, состоящая из целых чисел. Требуется найти для каждого столбца матрицы минимальное значение среди всех элементов этого столбца. Результатом выполнения задачи должен стать вектор размерности N, элементы которого соответствуют найденным минимальным значениям для каждого столбца исходной матрицы.

## Описание алгоритма
Алгоритм поиска минимальных значений по столбцам матрицы реализует поэлементное сравнение всех элементов каждого столбца для нахождения наименьшего значения.
1.	Создается вектор, куда будет записываться результат, размером N (равен количеству столбцов) и каждый элемент вектора инициализируется максимальным значением типа int (INT_MAX)
2.	Проходим по двум циклам (для каждого столбца j от 0 до N-1, для каждой строки i от 0 до M-1), где сравниваем текущий элемент матрицы с сохраненным минимумом. Если он меньше, то обновляем минимум
3.	Возвращаем вектор, куда записывался результат, с минимальными значениями для каждого столбца

## Описание схемы параллельного алгоритма
Параллельная версия использует распределение столбцов между MPI-процессами
1.	Корневой процесс (rank 0) распределяет столбцы матрицы между процессами
2.	Каждый процесс независимо находит минимумы по столбцам для назначенных ему столбцов. В результате каждый процесс формирует вектор минимумов
3.	Процессы отправляют свои локальные минимумы корневому процессу
4.	Корневой процесс объединяет все локальные минимумы в итоговый вектор

## Описание MPI-версии
Каждый MPI процесс получает свой диапозон столбцов для обработки, чтобы равномерно распределить нагрузку.
Затем проводились локальные вычисления минимальных значений
Сбор результатов с помощью MPI_Gatherv (эта функция позволяет собирать переменное количество данных от каждого процесса и объединяет в итоговый вектор на кроневом процессе)
Для корректной работы функциорнальных тестов результаты рассылаются всем процессам с помощью MPI_Bcast

## Результаты экспериментов
Для оценки эффективности параллельного алгоритма тест проводился матрице 100×100 (заполняли матрицу положительными уникальными числами       (i + j + 1))
             Результаты:
   алгоритм              время выполнения (с)
последовательный         0.0000297600
параллельный             0.0000184800

Корректность проверена с помощью функциональных тестах на матрицах разных размеров

## Выводы
MPI реализация показывает ускорение примерно в 1.6 раз по сравнению с последовательным алгоримом. 


## Заключение
В работе был разработан и реализован параллельный алгоритм поиска минимальных значений по столбцам матрицы, основывающийся на технологии MPI. Это решение не только показало полную корректность расчетов, но и подтвердило свою высокую производительность, что делает его применимым для обработки больших массивов данных.
