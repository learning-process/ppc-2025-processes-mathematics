# <Интегрирование – метод Монте-Карло>

- Студент: <Краснопевцева Вероника Дмитриевна>, группа <3823Б1ПМоп3>
- Технологии: <SEQ | MPI >
- Вариант: <21>

## 1. Введение
Численное интегрирование является фундаментальной задачей вычислительной математики. Для сложных функций, не имеющих аналитического решения, применяются численные методы. Метод Монте-Карло - мощный инструмент для численного интегрирования сложных функций, где аналитические методы затруднены. Он используется как для обычных определенных интегралов, так и для многомерных интегралов и ряда других математических задач.
Цель работы - реализация параллельной версии метода Монте-Карло для вычисления интеграла функции cos(x)·x³ с использованием MPI и сравнение эффективности с последовательной версией. 

## 2. Постановка задачи
### Задача: реализация последовательной (SEQ) и параллельной (MPI) версий метода Монте-Карло интегрирования нелинейной функции.
Функция f(x) = cos(x)*x*x*x демонстрирует осцилляционное поведение с возрастающей амплитудой, что делает ее интересным объектом для исследования методов численного интегрирования. Ее интеграл имеет аналитическое решение, что позволяет нам проверить корректность метода и исследовать погрешность при разных значениях.
\[
I = \int_{a}^{b} \cos(x) \cdot x^3  dx
\]

### Формат входных данных:
- Нижняя граница интегрирования a типа double
- Верхняя граница интегрирования b типа double
- Количество случайных точек n типа int, n > 0

### Формат выходных данных:
- Приближенное значение интеграла I типа double

### Ограничения:
- Интервал интегрирования должен быть корректным (a < b)
- Количество точек должно быть положительным
- Результат должен быть конечным числом

## 3. Описание алгоритма
### Базовый алгоритм Монте-Карло:

1. Задание границ интегрирования [a, b] и пределение количества точек n

2. Создание n равномерно распределенных по отрезку точек
   *В качестве генератора случайных чисел использовался псевдослучайный генератор вихрь Мерсенна(std::mt19937 gen(rd())) с функцией равномерного распределения точек от a до b c помощью std::uniform_real_distribution<double> dis(a, b).

3. Для каждой точки в цикле вычисляется значение подинтегральной функции и сумма этмх значений накапливается в переменной sum

4. Оценка интеграла по формуле I = (b-a)*sum/n

При достаточно большом n оценка стремится к истинному значению интеграла. Погрешность метода имеет порядок O(1/sqrt(n)).

## 4. Схема распараллеливания
### Основная нагрузка
Основной нагрузкой на метод является именно большое количество случайных точек на интервале для хорошей точности, поэтому было реализовано распределение данных как распределение количества точек между процессами.
### Распределение количества точек
количество точек процессу = общее кол-во точек / число потоков.
остаток = остаток от деления общего кол-ва точек на число потоков.
если ранг процесса < остатка => то количество точек процессу увеличивается на 1.
### Равномерное распределение точек
Начальное значение для генератора псевдослучайных чисел разное для каждого процесса (std::mt19937 gen(std::random_device{}() + rank)), чтобы обеспечить разные последовательности между процессами в одном запуске.

Процесс 0:    Процесс 1:    Процесс 2:   Процесс 3:
    \/           \/            \/            \/
Генерация     Генерация     Генерация     Генерация
точек         точек         точек         точек
    |             |             |             |
Вычисление    Вычисление    Вычисление    Вычисление
local_sum     local_sum     local_sum     local_sum
    |             |             |             |
    |---------------- MPI_Reduce--------------| 
                        ||
                        \/
                Процесс 0 вычисляет
                integral = (b-a)*global_sum/n
                        ||
                        \/
     ---------------MPI_Bcast--------------------- 
                        ||
                        \/
            Все процессы получают результат

## 5. Детали реализации 

Ключевые классы и функции: 
- класс KrasnopevtsevaV_MCIntegrationMPI с реализацией параллельной версии метода
- класс KrasnopevtsevaV_MCIntegrationSEQ с реализацией параллельной версии метода
- определение пространства имен namespace krasnopevtseva_v_monte_carlo_integration с определеним используемых типов данных:
    using InType = std::tuple<double, double, int>; - тип входных данных
                                |       |      |
                        граница a   граница b  число точек
    using OutType = double; - тип возвращаемых данных(значение интеграла)
    using TestType = std::tuple<std::tuple<double, double, int>, std::string>;
                                            |       |      |                |
                                    граница a   граница b  число точек   название теста
    using BaseTask = ppc::task::Task<InType, OutType>;

## 6. Окружение
- Windows: AMD Ryzen 7 5700X 8-Core Processor, 32.0 ГБ, Windows 11 Pro 25H2
- Набор инструментов: DevContainer:compiler gcc (Ubuntu 13.3.0-6ubuntu2~24.04) 13.3.0, Open MPI 4.1.6, build type Release

## 7. Результаты

### 7.1 Корректность
Было найдено аналитическое решение интеграла для сравнения корректности результата. 
Погрешность считалась по формуле tolerance = (b - a) / sqrt(points) * 10 
Точность решения ухудшается при выходе из интервала интегрирования [-2,2] потому что после этих значений график функции сильно растягивается - при выходе за эти границы увеличиваем допустимую погрешность.

### 7.2 Performance


| Mode        | Count | Time,ms | Speedup | Efficiency |
|-------------|-------|---------|---------|------------|
| seq         | 1     | 64      | 1.00    | N/A        |
| omp         | 2     | 17      | 1.88    | 94.0%      |
| omp         | 4     | 34      | 3.76    | 94.0%      |

Расчеты:
Speedup = T_seq / T_parallel
Для 2 процессов: 64 / 34 = 1.88
Для 4 процессов: 64 / 17 = 3.76

Efficiency = Speedup / Count × 100%
Для 2 процессов: 1.88 / 2 × 100% = 94.0%
Для 4 процессов: 3.76 / 4 × 100% = 94.0%

## 8. Conclusions

Вывод: Реализация интегрирования методом Монте-Карло демонстрирует отличную масштабируемость и может эффективно использоваться на многопроцессорных системах.

## 9. Приложения
```cpp
bool KrasnopevtsevaV_MCIntegrationMPI::RunImpl() {
  const auto &input = GetInput();
  double a = std::get<0>(input);
  double b = std::get<1>(input);
  int num_points = std::get<2>(input);

  if (a > b || num_points <= 0) {
    return false;
  }

  int rank, size;
  MPI_Comm_rank(MPI_COMM_WORLD, &rank);
  MPI_Comm_size(MPI_COMM_WORLD, &size);
  int local_points = num_points / size;
  int remainder = num_points % size;

  if (rank < remainder) {
    local_points++;
  }
  double local_sum = 0.0;
  std::mt19937 gen(std::random_device{}() + rank);
  std::uniform_real_distribution<double> dis(a, b);

  for (int i = 0; i < local_points; i++) {
    double x = dis(gen);
    double fx = std::cos(x) * x * x * x;
    local_sum += fx;
  }
  double global_sum = 0.0;
  MPI_Reduce(&local_sum, &global_sum, 1, MPI_DOUBLE, MPI_SUM, 0, MPI_COMM_WORLD);
  double integral = 0.0;
  if (rank == 0) {
    integral = (b - a) * global_sum / num_points;
  }
  MPI_Bcast(&integral, 1, MPI_DOUBLE, 0, MPI_COMM_WORLD);
  GetOutput() = integral;
  return true;
}
```